{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-18T11:56:29.312585Z",
     "start_time": "2023-09-18T11:56:28.736057Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir, getcwd, rename, makedirs, remove\n",
    "from os.path import isfile, join, isdir, exists\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import pyspark.pandas as pd\n",
    "from tqdm import tqdm\n",
    "import subprocess as sp\n",
    "from fuzzywuzzy import process, fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Common functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bb1b31a7945f1df"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def get_dirs(path):\n",
    "    return [f for f in listdir(path) if isdir(join(path, f))]\n",
    "\n",
    "def get_files(path):\n",
    "    return [join(path, f) for f in listdir(path) if isfile(join(path, f)) and f.endswith(\".tsv\")]\n",
    "\n",
    "def read_metadata_without_fields(path):\n",
    "    metadata = pd.read_csv(path, sep='\\t', na_values=\"\", low_memory=False)\n",
    "    if 'Field' in metadata.columns:\n",
    "        metadata = metadata.loc[metadata.Field.str.startswith('#') != True,].reset_index(drop=True)\n",
    "        metadata = metadata.drop('Field', axis=1)\n",
    "    return metadata\n",
    "\n",
    "def read_metadata_with_fields(path):\n",
    "    metadata = pd.read_csv(path, sep='\\t', na_values=\"\", low_memory=False)\n",
    "    return metadata\n",
    "\n",
    "def sort_case_insensitive(sort_list):\n",
    "    return sorted(sort_list, key=str.casefold)\n",
    "\n",
    "def get_hugo2ncbi():\n",
    "    hugo2ncbi = pd.read_csv(\"hugo_to_ncbi.txt\", sep='\\t')\n",
    "    hugo2ncbi[\"NCBI Gene ID\"] = hugo2ncbi[\"NCBI Gene ID\"].fillna(0).astype(int)\n",
    "    hugo2ncbi[\"NCBI Gene ID(supplied by NCBI)\"] = hugo2ncbi[\"NCBI Gene ID(supplied by NCBI)\"].fillna(0).astype(int)\n",
    "    \n",
    "    hugo2ncbi[\"NCBI Gene ID\"] = np.where(hugo2ncbi[\"NCBI Gene ID\"]!=0, hugo2ncbi[\"NCBI Gene ID\"], hugo2ncbi[\"NCBI Gene ID(supplied by NCBI)\"]) \n",
    "    hugo2ncbi['RefSeq IDs'] = np.where(hugo2ncbi[\"RefSeq IDs\"].fillna('')!='', hugo2ncbi[\"RefSeq IDs\"], hugo2ncbi[\"RefSeq(supplied by NCBI)\"].fillna('')) \n",
    "    \n",
    "    hugo2ncbi = hugo2ncbi[hugo2ncbi[\"NCBI Gene ID\"]!=0]\n",
    "    return hugo2ncbi\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T11:56:29.354852Z",
     "start_time": "2023-09-18T11:56:28.770322Z"
    }
   },
   "id": "a0aea3aa86a595bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Common env"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a8acee6cfcb14d2"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "start_dir = getcwd()\n",
    "home = \"/Users/tushar/CancerModels/pdxfinder-data/data/UPDOG/\"\n",
    "out_path = \"/Users/tushar/CancerModels/utils/cbioportal/pdcm-cbioportal/study/\"\n",
    "providers = sorted(get_dirs(home))\n",
    "reference_df = get_hugo2ncbi()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T11:56:29.486256Z",
     "start_time": "2023-09-18T11:56:28.782078Z"
    }
   },
   "id": "cf49fa885fd3209"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate data for cBioPortal"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80a507417a7f573d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate case lists"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2817d45050b3a0d"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "CASE_LIST_CONFIG_HEADER_COLUMNS = [\"CASE_LIST_FILENAME\", \"STAGING_FILENAME\", \"META_STABLE_ID\", \"META_CASE_LIST_CATEGORY\", \"META_CANCER_STUDY_ID\", \"META_CASE_LIST_NAME\", \"META_CASE_LIST_DESCRIPTION\"]\n",
    "CASE_LIST_UNION_DELIMITER = \"|\"\n",
    "CASE_LIST_INTERSECTION_DELIMITER = \"&\"\n",
    "MUTATION_STAGING_GENERAL_PREFIX = \"data_mutations\"\n",
    "SEQUENCED_SAMPLES_FILENAME = \"sequenced_samples.txt\"\n",
    "MUTATION_CASE_LIST_META_HEADER = \"sequenced_samples\"\n",
    "MUTATION_CASE_ID_COLUMN_HEADER = \"Tumor_Sample_Barcode\"\n",
    "SAMPLE_ID_COLUMN_HEADER = \"SAMPLE_ID\"\n",
    "NON_CASE_IDS = frozenset([\"MIRNA\", \"LOCUS\", \"ID\", \"GENE SYMBOL\", \"ENTREZ_GENE_ID\", \"HUGO_SYMBOL\", \"LOCUS ID\", \"CYTOBAND\", \"COMPOSITE.ELEMENT.REF\", \"HYBRIDIZATION REF\"])\n",
    "CANCER_STUDY_TAG = \"<CANCER_STUDY>\"\n",
    "NUM_CASES_TAG = \"<NUM_CASES>\"\n",
    "\n",
    "def generate_case_lists(case_list_config_filename, case_list_dir, study_dir, study_id, overwrite=False, verbose=False):\n",
    "    header = []\n",
    "    with open(case_list_config_filename, 'r') as case_list_config_file:\n",
    "        # get header and validate\n",
    "        header = case_list_config_file.readline().rstrip('\\n').rstrip('\\r').split('\\t')\n",
    "        # check full header matches what we expect\n",
    "        for column in CASE_LIST_CONFIG_HEADER_COLUMNS:\n",
    "            if column not in header:\n",
    "                print >> sys.stderr, \"ERROR: column '%s' is not in '%s'\" % (column, case_list_config_filename)\n",
    "                sys.exit(2)\n",
    "\n",
    "        for line in case_list_config_file:\n",
    "            line = line.rstrip('\\n').rstrip('\\r')\n",
    "            config_fields = line.split('\\t')\n",
    "            case_list_filename = config_fields[header.index(\"CASE_LIST_FILENAME\")]\n",
    "            staging_filename_list = config_fields[header.index(\"STAGING_FILENAME\")]\n",
    "            case_list_file_full_path = os.path.join(case_list_dir, case_list_filename)\n",
    "            if os.path.isfile(case_list_file_full_path) and not overwrite:\n",
    "                if verbose:\n",
    "                    print(\"LOG: generate_case_lists(), '%s' exists and overwrite is false, skipping caselist...\" % (case_list_filename))\n",
    "                continue\n",
    "\n",
    "            # might be single staging file\n",
    "            staging_filenames = []\n",
    "            # union (like all cases)\n",
    "            union_case_list = CASE_LIST_UNION_DELIMITER in staging_filename_list\n",
    "            # intersection (like complete or cna-seq)\n",
    "            intersection_case_list = CASE_LIST_INTERSECTION_DELIMITER in staging_filename_list\n",
    "            delimiter = CASE_LIST_UNION_DELIMITER if union_case_list else CASE_LIST_INTERSECTION_DELIMITER\n",
    "            staging_filenames = staging_filename_list.split(delimiter)\n",
    "            if verbose:\n",
    "                print(\"LOG: generate_case_lists(), staging filenames: %s\" % (\",\".join(staging_filenames)))\n",
    "\n",
    "            # if this is intersection all staging files must exist\n",
    "            if intersection_case_list and \\\n",
    "                    not all([os.path.isfile(os.path.join(study_dir, intersection_filename)) for intersection_filename in staging_filenames]):\n",
    "                continue\n",
    "\n",
    "            # this is the set we will pass to write_case_list_file\n",
    "            case_set = set([])\n",
    "            # this indicates the number of staging files processed -\n",
    "            # used to verify that an intersection should be written\n",
    "            num_staging_files_processed = 0\n",
    "            for staging_filename in staging_filenames:\n",
    "                if verbose:\n",
    "                    print(\"LOG: generate_case_lists(), processing staging file '%s'\" % (staging_filename))\n",
    "                # compute the case set\n",
    "                case_list = []\n",
    "                case_list = get_case_list_from_staging_file(study_dir, staging_filename, verbose)\n",
    "\n",
    "                if len(case_list) == 0:\n",
    "                    if verbose:\n",
    "                        print(\"LOG: generate_case_lists(), no cases in '%s', skipping...\" % (staging_filename))\n",
    "                    continue\n",
    "\n",
    "                if intersection_case_list:\n",
    "                    if len(case_set) == 0:\n",
    "                        # it is empty so initialize it\n",
    "                        case_set = set(case_list)\n",
    "                    else:\n",
    "                        case_set = case_set.intersection(case_list)\n",
    "                else:\n",
    "                    # union of files or single file\n",
    "                    case_set = case_set.union(case_list)\n",
    "\n",
    "                num_staging_files_processed += 1\n",
    "\n",
    "            # write case list file (don't make empty case lists)\n",
    "            if len(case_set) > 0:\n",
    "                if verbose:\n",
    "                    print(\"LOG: generate_case_lists(), calling write_case_list_file()...\")\n",
    "\n",
    "                # do not write out complete cases file unless we've processed all the files required\n",
    "                if intersection_case_list and num_staging_files_processed != len(staging_filenames):\n",
    "                    if verbose:\n",
    "                        print(\"LOG: generate_case_lists(), number of staging files processed (%d) != number of staging files required (%d) for '%s', skipping call to write_case_list_file()...\" % (num_staging_files_processed, len(staging_filenames), case_list_filename))\n",
    "                else:\n",
    "                    write_case_list_file(header, config_fields, study_id, case_list_file_full_path, case_set, verbose)\n",
    "            elif verbose:\n",
    "                print(\"LOG: generate_case_lists(), case_set.size() == 0, skipping call to write_case_list_file()...\")\n",
    "\n",
    "def get_case_list_from_staging_file(study_dir, staging_filename, verbose):\n",
    "    if verbose:\n",
    "        print(\"LOG: get_case_list_from_staging_file(), '%s'\" % (staging_filename))\n",
    "\n",
    "    case_set = set([])\n",
    "\n",
    "    # if we are processing mutations data and a SEQUENCED_SAMPLES_FILENAME exists, use it\n",
    "    if MUTATION_STAGING_GENERAL_PREFIX in staging_filename:\n",
    "        sequenced_samples_full_path = os.path.join(study_dir, SEQUENCED_SAMPLES_FILENAME)\n",
    "        if os.path.isfile(sequenced_samples_full_path):\n",
    "            if verbose:\n",
    "                print(\"LOG: get_case_list_from_staging_file(), '%s' exists, calling get_case_list_from_sequenced_samples_file()\" % (SEQUENCED_SAMPLES_FILENAME))\n",
    "            return get_case_list_from_sequenced_samples_file(sequenced_samples_full_path, verbose)\n",
    "\n",
    "    staging_file_full_path = os.path.join(study_dir, staging_filename)\n",
    "    if not os.path.isfile(staging_file_full_path):\n",
    "        return []\n",
    "\n",
    "    # staging file\n",
    "    with open(staging_file_full_path, 'r') as staging_file:\n",
    "        id_column_index = 0\n",
    "        process_header = True\n",
    "        for line in staging_file:\n",
    "            line = line.rstrip('\\n')\n",
    "            if line.startswith('#'):\n",
    "                if line.startswith('#' + MUTATION_CASE_LIST_META_HEADER + ':'):\n",
    "                    # split will split on any whitespace, tabs or any number of consecutive spaces\n",
    "                    return line[len(MUTATION_CASE_LIST_META_HEADER)+2:].strip().split()\n",
    "                continue # this is a comment line, skip it\n",
    "            values = line.split('\\t')\n",
    "\n",
    "            # is this the header line?\n",
    "            if process_header:\n",
    "                # look for MAF file case id column header\n",
    "                # if this is not a MAF file and header contains the case ids, return here\n",
    "                # we are assuming the header contains the case ids because SAMPLE_ID_COLUMN_HEADER is missing\n",
    "                if MUTATION_CASE_ID_COLUMN_HEADER not in values and SAMPLE_ID_COLUMN_HEADER not in [x.upper() for x in values]:\n",
    "                    if verbose:\n",
    "                        print(\"LOG: get_case_list_from_staging_file(), this is not a MAF header but has no '%s' column, we assume it contains sample ids...\" % (SAMPLE_ID_COLUMN_HEADER))\n",
    "                    for potential_case_id in values:\n",
    "                        # check to filter out column headers other than sample ids\n",
    "                        if potential_case_id.upper() in NON_CASE_IDS:\n",
    "                            continue\n",
    "                        case_set.add(potential_case_id)\n",
    "                    break # got case ids from header, don't read the rest of the file\n",
    "                else:\n",
    "                    # we know at this point one of these columns exists, so no fear of ValueError from index method\n",
    "                    id_column_index = values.index(MUTATION_CASE_ID_COLUMN_HEADER) if MUTATION_CASE_ID_COLUMN_HEADER in values else [x.upper() for x in values].index(SAMPLE_ID_COLUMN_HEADER)\n",
    "                    if verbose:\n",
    "                        print(\"LOG: get_case_list_from_staging_file(), this is a MAF or clinical file, samples ids in column with index: %d\" % (id_column_index))\n",
    "                process_header = False\n",
    "                continue # done with header, move on to next line\n",
    "            case_set.add(values[id_column_index])\n",
    "\n",
    "    return list(case_set)\n",
    "\n",
    "def get_case_list_from_sequenced_samples_file(sequenced_samples_full_path, verbose):\n",
    "    if verbose:\n",
    "        print(\"LOG: get_case_list_from_sequenced_samples_file, '%s'\", sequenced_samples_full_path)\n",
    "\n",
    "    case_set = set([])\n",
    "    with open(sequenced_samples_full_path, 'r') as sequenced_samples_file:\n",
    "        for line in sequenced_samples_file:\n",
    "            case_set.add(line.rstrip('\\n'))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"LOG: get_case_list_from_sequenced_samples_file, case set size: %d\" % (len(case_set)))\n",
    "\n",
    "    return list(case_set)\n",
    "\n",
    "def write_case_list_file(case_list_config_header, case_list_config_fields, study_id, case_list_full_path, case_set, verbose):\n",
    "    if verbose:\n",
    "        print(\"LOG: write_case_list_file(), '%s'\" % (case_list_full_path))\n",
    "    with open(case_list_full_path, 'w') as case_list_file:\n",
    "        case_list_file.write(\"cancer_study_identifier: \" + study_id + \"\\n\")\n",
    "        stable_id = case_list_config_fields[case_list_config_header.index(\"META_STABLE_ID\")].replace(CANCER_STUDY_TAG, study_id)\n",
    "        case_list_file.write(\"stable_id: \" + stable_id + \"\\n\")\n",
    "        case_list_file.write(\"case_list_name: \" + case_list_config_fields[case_list_config_header.index(\"META_CASE_LIST_NAME\")] + \"\\n\")\n",
    "        case_list_description = case_list_config_fields[case_list_config_header.index(\"META_CASE_LIST_DESCRIPTION\")].replace(NUM_CASES_TAG, str(len(case_set)))\n",
    "        case_list_file.write(\"case_list_description: \" + case_list_description + \"\\n\")\n",
    "        case_list_file.write(\"case_list_category: \" + case_list_config_fields[case_list_config_header.index(\"META_CASE_LIST_CATEGORY\")] + \"\\n\")\n",
    "        case_list_file.write(\"case_list_ids: \" + '\\t'.join(case_set) + \"\\n\")\n",
    "\n",
    "def main(case_list_config_filename, case_list_dir, study_dir, study_id, overwrite, verbose):\n",
    "    '''\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-c', '--case-list-config-file', action = 'store', dest = 'case_list_config_file', required = True, help = 'Path to the case list configuration file.  An example can be found in \"test/resources/generate_case_lists/case_list_config.tsv\"')\n",
    "    parser.add_argument('-d', '--case-list-dir', action = 'store', dest = 'case_list_dir', required = True, help = 'Path to the directory in which the case list files should be written')\n",
    "    parser.add_argument('-s', '--study-dir', action = 'store', dest = 'study_dir', required = True, help = 'The directory that contains the cancer study genomic files')\n",
    "    parser.add_argument('-i', '--study-id', action = 'store', dest = 'study_id', required = True, help = 'The cancer study stable id')\n",
    "    parser.add_argument('-o', '--overwrite', action = 'store_true', dest = 'overwrite', required = False, help = 'When given, overwrite the case list files')\n",
    "    parser.add_argument('-v', '--verbose', action = 'store_true', dest = 'verbose', required = False, help = 'When given, be verbose')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    #case_list_config_filename = args.case_list_config_file\n",
    "    #case_list_dir = args.case_list_dir\n",
    "    #study_dir = args.study_dir\n",
    "    #study_id = args.study_id\n",
    "    overwrite = args.overwrite\n",
    "    verbose = args.verbose\n",
    "    '''\n",
    "    if verbose:\n",
    "        print(\"LOG: case_list_config_file='%s'\" % (case_list_config_filename))\n",
    "        print(\"LOG: case_list_dir='%s'\" % (case_list_dir))\n",
    "        print(\"LOG: study_dir='%s'\" % (study_dir))\n",
    "        print(\"LOG: study_id='%s'\" % (study_id))\n",
    "        print(\"LOG: overwrite='%s'\" % (overwrite))\n",
    "        print(\"LOG: verbose='%s'\" % (verbose))\n",
    "\n",
    "    if not os.path.isfile(case_list_config_filename):\n",
    "        print(\"ERROR: case list configuration file '%s' does not exist or is not a file\" % (case_list_config_filename), file=sys.stderr)\n",
    "        sys.exit(2)\n",
    "\n",
    "    if not os.path.isdir(case_list_dir):\n",
    "        print(\"ERROR: case list file directory '%s' does not exist or is not a directory\" % (case_list_dir), file=sys.stderr)\n",
    "        sys.exit(2)\n",
    "\n",
    "    if not os.path.isdir(study_dir):\n",
    "        print(\"ERROR: study directory '%s' does not exist or is not a directory\" % (study_dir), file=sys.stderr)\n",
    "        sys.exit(2)\n",
    "\n",
    "    generate_case_lists(case_list_config_filename, case_list_dir, study_dir, study_id, overwrite, verbose)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T11:56:29.522392Z",
     "start_time": "2023-09-18T11:56:29.331065Z"
    }
   },
   "id": "e355eb97a06130ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clinical files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89db2700e60714bc"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def add_headers_clinical_patient():\n",
    "    # Column headers - The attribute Display Names: The display name for each clinical attribute\n",
    "    column_headers = [\"#Patient Identifier\", \"Sex\", \"Diagnosis Age\", \"Overall Survival (Months)\", \"Overall Survival Status\"]\n",
    "    # Column descriptions - The attribute Descriptions: Long(er) description of each clinical attribute\n",
    "    column_description = [\"#Identifier to uniquely specify a patient.\", \"Sex\", \"Age at which a condition or disease was first diagnosed.\", \"Overall survival in months since initial diagonosis.\", \"Overall patient survival status.\"]\n",
    "    # Column data type - The attribute Datatype: The datatype of each clinical attribute (must be one of: STRING, NUMBER, BOOLEAN)\n",
    "    column_data_type = [\"#STRING\", \"STRING\", \"NUMBER\", \"NUMBER\", \"STRING\"]\n",
    "    # Column priority - A number which indicates the importance of each attribute. A higher number indicates a higher priority.\n",
    "    column_priority = [\"#1\", \"1\", \"1\", \"1\", \"1\"]\n",
    "    # Column headers for validation\n",
    "    column_header_validation = [\"PATIENT_ID\", \"SEX\", \"AGE\", \"OS_MONTHS\", \"OS_STATUS\"]\n",
    "    return [column_headers, column_description, column_data_type, column_priority, column_header_validation]\n",
    "\n",
    "def add_headers_clinical_sample():\n",
    "    # Column headers - The attribute Display Names: The display name for each clinical attribute\n",
    "    column_headers = [\"#Patient Identifier\", \"Sample Identifier\", \"Tumor Type\", \"Cancer Type\", \"Cancer Type Detailed\", \"Primary site\", \"Tumor Grade\", \"Model type\", \"Model ID\"]\n",
    "    # Column descriptions - The attribute Descriptions: Long(er) description of each clinical attribute\n",
    "    column_description = [\"#Identifier to uniquely specify a patient.\", \"A unique sample identifier.\", \"The type of tumour sample (i.e., normal, primary, met, recurrence).\", \"Cancer Type\", \"Cancer Type Detailed\", \"Site of the primary tumor where primary cancer is originating from (may not correspond to the site of the current tissue sample). No abbreviations.\", \"The implanded tumour grade value.\", \"Type of patient derived cancer model\", \"Unique identifier for the PDCMs\"]\n",
    "    # Column data type - The attribute Datatype: The datatype of each clinical attribute (must be one of: STRING, NUMBER, BOOLEAN)\n",
    "    column_data_type = [\"#STRING\", \"STRING\", \"STRING\", \"STRING\", \"STRING\", \"STRING\", \"STRING\", \"STRING\", \"STRING\"]\n",
    "    # Column priority - A number which indicates the importance of each attribute. A higher number indicates a higher priority.\n",
    "    column_priority = [\"#1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\"]\n",
    "    # Column headers for validation\n",
    "    column_header_validation = [\"PATIENT_ID\", \"SAMPLE_ID\", \"SAMPLE_TYPE\", \"CANCER_TYPE\", \"CANCER_TYPE_DETAILED\", \"PRIMARY_SITE\", \"TUMOR_GRADE\", \"MODEL_TYPE\", \"MODEL_ID\"]\n",
    "    return [column_headers, column_description, column_data_type, column_priority, column_header_validation]\n",
    "\n",
    "def generate_clinical_df(headers):\n",
    "    # Generate the df\n",
    "    c_bio_data_clinical = pd.DataFrame(columns = headers[0])\n",
    "    c_bio_data_clinical.loc[0, :] = headers[1]\n",
    "    c_bio_data_clinical.loc[1, :] = headers[2]\n",
    "    c_bio_data_clinical.loc[2, :] = headers[3]\n",
    "    c_bio_data_clinical.loc[3, :] = headers[4]\n",
    "    return c_bio_data_clinical\n",
    "\n",
    "def write_clinical_file(out_df, out_path, file_type):\n",
    "    out_file = join(out_path, \"data_clinical_\"+file_type+\".txt\")\n",
    "    out_df.to_csv(out_file, sep=\"\\t\", index=False)\n",
    "\n",
    "def clinical_patient_data_transformation(data_path, provider, out_path):\n",
    "    out_df = generate_clinical_df(add_headers_clinical_patient())\n",
    "    data_path = join(data_path, provider+\"_metadata-patient.tsv\")\n",
    "    \n",
    "    mapper = {\"patient_id\": \"#Patient Identifier\", \"sex\": \"Sex\", \"age_at_initial_diagnosis\": \"Diagnosis Age\"}\n",
    "    temp = read_metadata_without_fields(data_path).rename(columns = mapper)\n",
    "    \n",
    "    temp[\"Overall Survival (Months)\"] = \"\"\n",
    "    temp[\"Overall Survival Status\"] = \"\"\n",
    "    cs = pd.read_csv(join(out_path, \"data_clinical_sample.txt\"), sep=\"\\t\")\n",
    "    patient_ids = list(cs[\"#Patient Identifier\"])\n",
    "    temp = temp[temp[\"#Patient Identifier\"].isin(patient_ids)]\n",
    "    #temp = temp.merge(cs[[\"#Patient Identifier\", \"Cancer Type\"]], on=\"#Patient Identifier\", how=\"inner\")\n",
    "    #temp[\"Tumor Type\"] = temp[\"Cancer Type\"]\n",
    "    out_df = pd.concat([out_df, temp[out_df.columns]], ignore_index=True)\n",
    "    \n",
    "    return out_df.replace(\"(?i)not provided\", \"\", regex=True).replace(\"(?i)not collected\", \"\", regex=True).drop_duplicates(subset=[\"#Patient Identifier\"])\n",
    "\n",
    "def clinical_patient_sample_data_transformation(data_path, provider):\n",
    "    out_df = generate_clinical_df(add_headers_clinical_sample())\n",
    "    data_path = join(data_path, provider+\"_metadata-patient_sample.tsv\")\n",
    "    \n",
    "    mapper = {\"patient_id\":\"#Patient Identifier\", \"sample_id\":\"Sample Identifier\", \"tumour_type\":\"Tumor Type OG\", \n",
    "              \"primary_site\": \"Primary site OG\", \"grade\":\"Tumor Grade\"}\n",
    "    temp = read_metadata_without_fields(data_path).rename(columns = mapper)\n",
    "    temp = temp.merge(get_meta_from_api(provider), on=\"model_id\", how=\"inner\").reset_index(drop=True)\n",
    "    temp[\"Cancer Type\"] = temp[\"cancer_system\"]\n",
    "    temp[\"Cancer Type Detailed\"] = temp[\"histology\"]\n",
    "    temp[\"Model type\"] = temp[\"type\"]\n",
    "    temp[\"Tumor Type\"] = temp[\"tumor_type\"]\n",
    "    temp[\"Primary site\"] = temp[\"primary_site\"]\n",
    "    temp[\"Model ID\"] = temp[\"model_id\"]\n",
    "    temp[\"Tumor Grade\"] = temp[\"Tumor Grade\"].str.replace('Not provided', '', flags=re.IGNORECASE).str.replace('Not collected', '', flags=re.IGNORECASE).replace(\"p.*\", \"\", regex=True).replace(\"T.*\", \"\", regex=True).replace(\" \\(.*\", \"\", regex=True).replace(\";.*\", \"\", regex=True).str.replace('Not collected', '', flags=re.IGNORECASE).replace(\"Moderate\", \"moderately differentiated\", regex=True).replace(\"Poorly\", \"poorly differentiated\", regex=True).replace(\"Well\", \"well differentiated\", regex=True).replace(\"High-Grade\", \"high\", regex=True).replace(\"High grade\", \"high\", regex=True).replace(\"Grade \", \"G\", regex=True)\n",
    "    out_df = pd.concat([out_df, temp[out_df.columns]], ignore_index=True)\n",
    "    return out_df.replace(\"(?i)not provided\", \"\", regex=True).replace(\"(?i)not collected\", \"\", regex=True).drop_duplicates(subset=[\"#Patient Identifier\", \"Sample Identifier\"])\n",
    "\n",
    "def get_meta_from_api(provider_name):\n",
    "    df = pd.read_json(\"https://www.cancermodels.org/api/model_metadata?data_source=eq.\"+provider_name)\n",
    "    return df[[\"model_id\", \"cancer_system\", \"histology\", \"type\", \"tumor_type\", \"primary_site\"]]\n",
    "\n",
    "def generate_clinical_patient(in_path, out_path, provider):\n",
    "    write_clinical_file(clinical_patient_data_transformation(in_path, provider, out_path), out_path, \"patient\")\n",
    "    \n",
    "def generate_clinical_sample(in_path, out_path, provider):\n",
    "    write_clinical_file(clinical_patient_sample_data_transformation(in_path, provider), out_path, \"sample\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T11:56:29.522652Z",
     "start_time": "2023-09-18T11:56:29.429705Z"
    }
   },
   "id": "e104df4ab4a8f04a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Molecular data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6a05e1da3fa0f6b"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def get_platform(path, type):\n",
    "    df = read_metadata_without_fields(path).fillna(\"\")\n",
    "    df = df[df[\"molecular_characterisation_type\"]==type]\n",
    "    df[\"platform_name\"] = df[\"library_strategy\"]+ \" -  \" +df[\"instrument_model\"]\n",
    "    if path.__contains__(\"JAX\"):\n",
    "        if type==\"mutation\":\n",
    "            return \"WES\"\n",
    "        if type==\"expression\":\n",
    "            return \"RNA-Seq\"\n",
    "        if type==\"copy number alteration\":\n",
    "            return \"SNP\"\n",
    "    return \", \".join(df[\"platform_name\"])\n",
    "\n",
    "def filter_sample_ids(x, sample_ids):\n",
    "    out = [val for val in sample_ids if val in x]\n",
    "    if len(out)>0 and out[0]!='':\n",
    "        return out[0]\n",
    "    else:\n",
    "        \"No match\"\n",
    "\n",
    "def filter_samples(df, col, out_path):\n",
    "    sample_ids = list(pd.read_csv(join(out_path, \"data_clinical_sample.txt\"), sep=\"\\t\")[\"Sample Identifier\"])[4:]\n",
    "    df = df[df[col].apply(lambda x: any(val in x for val in sample_ids))]\n",
    "    df[col] = df[col].apply(lambda x: filter_sample_ids(x, sample_ids))\n",
    "    df = df[df[col]!=\"No match\"]\n",
    "    df = df[df[col].fillna('')!=\"\"]\n",
    "    return df\n",
    "    \n",
    "def read_mol_data(path):\n",
    "    files = get_files(path)\n",
    "    if len(files) == 0:\n",
    "        dirs = get_dirs(path)\n",
    "        for dir in dirs:\n",
    "            files.append(get_files(join(path,dir)))\n",
    "        files = [item for sublist in files for item in sublist]\n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        temp = pd.read_csv(file, sep=\"\\t\")\n",
    "        df = pd.concat([df, temp], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def compute_end_pos(df):\n",
    "    df[\"End_Position\"] = pd.to_numeric(df[\"Start_Position\"]) + np.where(df.Reference_Allele.str.len()>=df.Tumor_Seq_Allele2.str.len(), df.Reference_Allele.str.len(), df.Tumor_Seq_Allele2.str.len()) - 1\n",
    "    return df\n",
    "\n",
    "def map_gene_symbol_to_id(symbol):\n",
    "    # Check if the symbol is in the reference DataFrame\n",
    "    if symbol in reference_df['Approved symbol'].tolist():\n",
    "        return reference_df.loc[reference_df['Approved symbol'] == symbol, 'NCBI Gene ID'].values[0]\n",
    "    # Check if the symbol is in the 'previous' column\n",
    "    elif reference_df['Previous symbols'].str.contains(symbol, na=False).any():\n",
    "        return reference_df.loc[reference_df['Previous symbols'].str.contains(symbol, na=False), 'NCBI Gene ID'].values[0]\n",
    "    # Check if the symbol is in the 'alias' column\n",
    "    elif reference_df['Alias symbols'].str.contains(symbol, na=False).any():\n",
    "        return reference_df.loc[reference_df['Alias symbols'].str.contains(symbol, na=False), 'NCBI Gene ID'].values[0]\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def map_id_to_hugo(id, symbol):\n",
    "    if id==\"\":\n",
    "        return symbol\n",
    "    return reference_df.loc[reference_df['NCBI Gene ID'] == id, 'Approved symbol'].values[0]\n",
    "\n",
    "def map_id_to_refseq(id):\n",
    "    if id==\"\":\n",
    "        return \"\"\n",
    "    else:\n",
    "        return reference_df.loc[reference_df['NCBI Gene ID'] == id, 'RefSeq IDs'].values[0]\n",
    "\n",
    "def handle_frameshift(row):\n",
    "    if not row[\"Consequence\"].__contains__(\"frameshift\"):\n",
    "        return row\n",
    "    variant = row[\"variant_class\"]\n",
    "    if variant.__contains__(\"frameshift\"):\n",
    "        if row[\"coding_sequence_change\"].__contains__(\"ins\"):\n",
    "            variant = \"insertion\"\n",
    "        elif row[\"coding_sequence_change\"].__contains__(\"del\"):\n",
    "            variant = \"deletion\"\n",
    "    row[\"Consequence\"] = \"frameshift_variation_\" + variant\n",
    "    return row\n",
    "\n",
    "def generate_variation_classification(df):\n",
    "    mapper = {\"frameshift_variant_deletion\":\"Frame_Shift_Del\", \n",
    "              \"frameshift_variant_insertion\":\"Frame_Shift_Ins\", \n",
    "              \"inframe_deletion\":\"In_Frame_Del\", \n",
    "              \"inframe_insertion\": \"In_Frame_Ins\", \n",
    "              \"missense_variant\": \"Missense_Mutation\", \n",
    "              \"stop_gained\": \"Nonsense_Mutation\", \n",
    "              \"5_prime_UTR_variant\": \"5'UTR\", \n",
    "              \"upstream_gene_variant\": \"5'Flank\", \n",
    "              \"downstream_gene_variant\": \"3'Flank\", \n",
    "              \"3_prime_UTR_variant\": \"3'UTR\", \n",
    "              \"non_coding_transcript_variant\": \"RNA\", \n",
    "              \"intron_variant\": \"Intron\", \n",
    "              \"splice_region_variant\": \"Splice_Region\", \n",
    "              \"synonymous_variant\": \"Silent\", \n",
    "              \"stop_lost\": \"Nonstop_Mutation\",\n",
    "              \"start_retained_variant\": \"Translation_Start_Site\",\n",
    "              \"intergenic_variant\": \"IGR\"}\n",
    "    # Targeted_Region, De_novo_Start_InFrame, De_novo_Start_OutOfFrame, Splice_Site (dup) }\n",
    "    #df[\"temp_cons\"] = np.where(df[\"Consequence\"].str.contains(\"frameshift\"), df[\"Consequence\"], df[\"Consequence\"])\n",
    "    df = df.apply(lambda x: handle_frameshift(x), axis=1)\n",
    "    df[\"Variant_Classification\"] = df[\"Consequence\"].apply(lambda x: mapper.get(x, \"Unknown\"))\n",
    "        #np.where(df[\"Consequence\"].to_list() in mapper.keys(), df[\"Consequence\"], \"Unknown\"))\n",
    "    df[\"Variant_Classification\"] = df[\"Variant_Classification\"].replace(mapper)\n",
    "    return df\n",
    "\n",
    "def generate_meta_mutation(study, out_path, platform):\n",
    "    meta_df = pd.DataFrame(columns=[0,1])\n",
    "    meta_df.loc[0,:] = [\"cancer_study_identifier:\", study]\n",
    "    meta_df.loc[1,:] = [\"genetic_alteration_type:\", \"MUTATION_EXTENDED\"]\n",
    "    meta_df.loc[2,:] = [\"datatype:\", \"MAF\"]\n",
    "    meta_df.loc[3,:] = [\"stable_id:\", \"mutations\"]\n",
    "    meta_df.loc[4,:] = [\"show_profile_in_analysis_tab:\", \"true\"]\n",
    "    meta_df.loc[5,:] = [\"profile_description:\", \"Mutation data from \"+platform]\n",
    "    meta_df.loc[6,:] = [\"profile_name:\", \"Mutations\"]\n",
    "    meta_df.loc[7,:] = [\"variant_classification_filter:\", \"De_novo_Start_InFrame, De_novo_Start_OutOfFrame, Unknown\"] \n",
    "    meta_df.loc[8,:] = [\"data_filename:\", \"data_mutations_extended.txt\"]\n",
    "    meta_df.to_csv(join(out_path, \"meta_mutations_extended.txt\"), sep=\"\\t\", index=False,header=False)\n",
    "\n",
    "def generate_mutation_data(path, out_path):\n",
    "    mapper={\"sample_id\": \"Tumor_Sample_Barcode\", \"seq_start_position\": \"Start_Position\", \"chromosome\":\"Chromosome\",\n",
    "            \"ref_allele\":\"Reference_Allele\", \"alt_allele\": \"Tumor_Seq_Allele2\", \"symbol\":\"Hugo_Symbol\",\n",
    "            \"consequence\":\"Consequence\", \"amino_acid_change\":\"HGVSp_Short\", \n",
    "            \"ensembl_gene_id\": \"Gene\",\"ensembl_transcript_id\":\"Transcript_ID\", \"codon_change\": \"Codons\", \"ncbi_transcript_id\": \"RefSeq\"}\n",
    "    mut_df = read_mol_data(path).rename(columns = mapper).fillna(\"\")\n",
    "    mut_df = filter_samples(mut_df, \"Tumor_Sample_Barcode\", out_path)\n",
    "    out_column = [\"Hugo_Symbol\", \"Entrez_Gene_Id\", \"Center\", \"NCBI_Build\", \"Chromosome\", \"Start_Position\", \"End_Position\", \"Strand\", \"Consequence\", \"Variant_Classification\", \"Variant_Type\", \"Reference_Allele\", \"Tumor_Seq_Allele2\", \"dbSNP_RS\", \"dbSNP_Val_Status\", \"Tumor_Sample_Barcode\", \"Matched_Norm_Sample_Barcode\", \"Match_Norm_Seq_Allele1\", \"Match_Norm_Seq_Allele2\", \"Tumor_Validation_Allele1\", \"Tumor_Validation_Allele2\", \"Match_Norm_Validation_Allele1\", \"Match_Norm_Validation_Allele2\", \"Verification_Status\", \"Validation_Status\", \"Mutation_Status\", \"Sequencing_Phase\", \"Sequence_Source\", \"Validation_Method\", \"Score\", \"BAM_File\", \"Sequencer\", \"t_ref_count\", \"t_alt_count\", \"n_ref_count\", \"n_alt_count\", \"HGVSc\", \"HGVSp\", \"HGVSp_Short\", \"Transcript_ID\", \"RefSeq\", \"Protein_position\", \"Codons\", \"Hotspot\"]\n",
    "    mut_df = compute_end_pos(mut_df)\n",
    "    mut_df[\"NCBI_Build\"] = \"GRCh38\"\n",
    "    mut_df[\"Strand\"] = \"+\"\n",
    "    mut_df[\"HGVSc\"] = mut_df[\"Transcript_ID\"]+\"c.\"+mut_df[\"coding_sequence_change\"]\n",
    "    mut_df['Protein_position'] = np.where(mut_df['HGVSp_Short'].fillna('')!='', mut_df['HGVSp_Short'].str[1:-1], '')\n",
    "    mut_df[\"HGVSp_Short\"] = np.where(mut_df[\"HGVSp_Short\"].fillna('')!=\"\", \"p.\"+mut_df[\"HGVSp_Short\"].str.replace('.0', ''), \"\")\n",
    "    mut_df[\"Entrez_Gene_Id\"] = mut_df['Hugo_Symbol'].apply(map_gene_symbol_to_id)\n",
    "    mut_df = mut_df[mut_df[\"Entrez_Gene_Id\"]!=\"\"]\n",
    "    mut_df['Hugo_Symbol'] = mut_df[[\"Entrez_Gene_Id\", 'Hugo_Symbol']].apply(lambda x: map_id_to_hugo(x[0], x[1]), axis=1)\n",
    "    mut_df['RefSeq'] = mut_df['Entrez_Gene_Id'].apply(map_id_to_refseq)\n",
    "    #mut_df[\"User_Amino_Acid_Change\"] = mut_df[\"HGVSp_Short\"] \n",
    "    mut_df = generate_variation_classification(mut_df)\n",
    "    \n",
    "    mut_df[\"Variant_Type\"] = mut_df[\"variant_class\"].replace(\"SNV\", \"SNP\").replace(\"insertion\", \"INS\").replace(\"deletion\", \"DEL\")\n",
    "    for column in out_column:\n",
    "        if column not in mut_df.columns:\n",
    "            mut_df[column] = \"\"\n",
    "    if mut_df.shape[0]>0:\n",
    "        mut_df[out_column].to_csv(join(out_path, \"data_mutations_extended.txt\"), index=False, sep=\"\\t\")\n",
    "    else:\n",
    "        remove(join(out_path, \"meta_mutations_extended.txt\"))\n",
    "        \n",
    "def generate_meta_cna(study, out_path, platform, datatype):\n",
    "    meta_df = pd.DataFrame(columns=[0,1])\n",
    "    meta_df.loc[0,:] = [\"cancer_study_identifier:\", study]\n",
    "    meta_df.loc[1,:] = [\"genetic_alteration_type:\", \"COPY_NUMBER_ALTERATION\"]\n",
    "    if datatype==\"log\":\n",
    "        meta_df.loc[2,:] = [\"datatype:\", \"LOG2-VALUE\"]\n",
    "        meta_df.loc[3,:] = [\"stable_id:\", \"log2CNA\"]\n",
    "        out_name=\"log2_cna\"\n",
    "        meta_df.loc[4,:] = [\"show_profile_in_analysis_tab:\", \"false\"]\n",
    "        meta_df.loc[5,:] = [\"profile_description:\", \"Putative copy-number from GISTIC 2.0. Values: -2 = homozygous deletion; -1 = hemizygous deletion; 0 = neutral / no change; 1 = gain; 2 = high level amplification. \"+platform]\n",
    "        meta_df.loc[6,:] = [\"profile_name:\", \"Putative copy-number alterations from GISTIC\"]\n",
    "        meta_df.loc[7,:] = [\"data_filename:\", \"data_log2_cna.txt\"]\n",
    "\n",
    "    elif datatype==\"gistic\":\n",
    "        meta_df.loc[2,:] = [\"datatype:\", \"DISCRETE\"]\n",
    "        meta_df.loc[3,:] = [\"stable_id:\", \"gistic\"]\n",
    "        out_name=\"cna\"\n",
    "        meta_df.loc[4,:] = [\"show_profile_in_analysis_tab:\", \"false\"]\n",
    "        meta_df.loc[5,:] = [\"profile_description:\", \"Log2 copy-number data from \"+platform]\n",
    "        meta_df.loc[6,:] = [\"profile_name:\", \"Log2 copy-number values\"]\n",
    "        meta_df.loc[7,:] = [\"data_filename:\", \"data_cna.txt\"]\n",
    "    meta_df.to_csv(join(out_path, \"meta_\"+out_name+\".txt\"), sep=\"\\t\", index=False,header=False)\n",
    "\n",
    "def generate_cna_data(path, out_path, study, platform):\n",
    "    df = read_mol_data(path)[[\"sample_id\", \"symbol\", \"log2r_cna\", \"gistic_value\"]]\n",
    "    col_value = \"log2r_cna\"\n",
    "    datatype=\"log\"\n",
    "    out_name=\"log2_cna\"\n",
    "    df = filter_samples(df, \"sample_id\", out_path)\n",
    "    df['Hugo_Symbol'] = df['symbol']\n",
    "    if df[col_value].isna().all():\n",
    "        col_value=\"gistic_value\"\n",
    "        datatype=\"gistic\"\n",
    "        out_name=\"cna\"\n",
    "        df['gistic_value'] = df['gistic_value'].astype(int)\n",
    "    elif df[col_value].isna().all():\n",
    "        return None\n",
    "    if datatype==\"gistic\":\n",
    "        df = df.pivot_table(index='Hugo_Symbol', columns='sample_id', values=col_value, aggfunc='first').fillna(100).astype(int).replace(100, 'NA').reset_index()\n",
    "    else: \n",
    "        df = df.pivot_table(index='Hugo_Symbol', columns='sample_id', values=col_value, aggfunc='first').fillna(\"NA\").reset_index()\n",
    "    out_cols = list(df.columns)\n",
    "    out_cols.insert(1, 'Entrez_Gene_Id')\n",
    "    df['Entrez_Gene_Id'] = df['Hugo_Symbol'].apply(map_gene_symbol_to_id)\n",
    "    df = df[df[\"Entrez_Gene_Id\"]!=\"\"]\n",
    "    df['Hugo_Symbol'] = df[[\"Entrez_Gene_Id\", 'Hugo_Symbol']].apply(lambda x: map_id_to_hugo(x[0], x[1]), axis=1)\n",
    "    if df.shape[0]>0:\n",
    "        generate_meta_cna(study, out_path, platform, datatype)\n",
    "        df[out_cols].to_csv(join(out_path, \"data_\"+out_name+\".txt\"), index=False, sep=\"\\t\")\n",
    "    #else:\n",
    "    #   remove(join(out_path,\"meta_log2_cna.txt\"))\n",
    "        \n",
    "def generate_meta_expression(study, out_path, platform, datatype):\n",
    "    meta_df = pd.DataFrame(columns=[0,1])\n",
    "    meta_df.loc[0,:] = [\"cancer_study_identifier:\", study]\n",
    "    meta_df.loc[1,:] = [\"genetic_alteration_type:\", \"MRNA_EXPRESSION\"]\n",
    "    if datatype==\"mrna\":\n",
    "        meta_df.loc[2,:] = [\"datatype:\", \"CONTINUOUS\"]\n",
    "        meta_df.loc[3,:] = [\"stable_id:\", \"rna_seq_mrna\"]\n",
    "    elif datatype==\"Zscore\":\n",
    "        meta_df.loc[2,:] = [\"datatype:\", \"Z-SCORE\"]\n",
    "        meta_df.loc[3,:] = [\"stable_id:\", \"mrna_median_Zscores\"]        \n",
    "    meta_df.loc[4,:] = [\"show_profile_in_analysis_tab:\", \"true\"]\n",
    "    meta_df.loc[5,:] = [\"profile_description:\", \"Expression data from \"+platform]\n",
    "    meta_df.loc[6,:] = [\"profile_name:\", \"Expression\"]\n",
    "    meta_df.loc[7,:] = [\"data_filename:\", \"data_mrna_seq_rpkm.txt\"]\n",
    "    meta_df.to_csv(join(out_path, \"meta_mrna_seq_rpkm.txt\"), sep=\"\\t\", index=False,header=False)\n",
    "\n",
    "def generate_expression_data(path, out_path, platform, study):\n",
    "    df = read_mol_data(path)[[\"sample_id\", \"symbol\", \"rnaseq_fpkm\", \"z_score\"]]\n",
    "    df = filter_samples(df, \"sample_id\", out_path)\n",
    "\n",
    "    df[\"Hugo_Symbol\"] = df[\"symbol\"]\n",
    "    no_fpkm = df['rnaseq_fpkm'].isna().all()\n",
    "    datatype=\"mrna\"\n",
    "    value_column = \"rnaseq_fpkm\"\n",
    "    if no_fpkm:\n",
    "        print(\"Using Z score: \"+path)\n",
    "        datatype = \"Zscore\"\n",
    "        value_column = \"z_score\"\n",
    "    df = df[[\"sample_id\", \"Hugo_Symbol\", value_column]]\n",
    "    df = df.pivot_table(index='Hugo_Symbol', columns='sample_id', values=value_column, aggfunc='first').fillna('NA').reset_index()\n",
    "    out_cols = list(df.columns)\n",
    "    out_cols.insert(1, 'Entrez_Gene_Id')\n",
    "    df['Entrez_Gene_Id'] = df['Hugo_Symbol'].apply(map_gene_symbol_to_id)\n",
    "    df = df[df[\"Entrez_Gene_Id\"]!=\"\"]\n",
    "    df['Hugo_Symbol'] = df[[\"Entrez_Gene_Id\", 'Hugo_Symbol']].apply(lambda x: map_id_to_hugo(x[0], x[1]), axis=1)\n",
    "    \n",
    "    if df.shape[0]>0:\n",
    "        generate_meta_expression(study, out_path, platform, datatype)\n",
    "        df[out_cols].to_csv(join(out_path, \"data_mrna_seq_rpkm.txt\"), sep=\"\\t\", index=False)\n",
    "    \n",
    "def generate_cna_files(in_path, study, provider, out_path):\n",
    "    platform = get_platform(join(in_path, provider+\"_molecular_metadata-platform.tsv\"), \"mutation\")\n",
    "    #generate_meta_cna(study, out_path, platform)\n",
    "    generate_cna_data(join(in_path, \"cna\"), out_path, study, platform)\n",
    "def generate_mutation_files(in_path, study, provider, out_path):\n",
    "    platform = get_platform(join(in_path, provider+\"_molecular_metadata-platform.tsv\"), \"mutation\")\n",
    "    generate_meta_mutation(study, out_path, platform)\n",
    "    generate_mutation_data(join(in_path, \"mut\"), out_path)\n",
    "def generate_expression_files(in_path, study, provider, out_path):\n",
    "    platform = get_platform(join(in_path, provider+\"_molecular_metadata-platform.tsv\"), \"expression\")\n",
    "    generate_expression_data(join(in_path, \"expression\"), out_path, platform, study)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T11:56:29.588162Z",
     "start_time": "2023-09-18T11:56:29.439435Z"
    }
   },
   "id": "7a87bdaebec9d3c6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Timeline data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55c12c360965f278"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def generate_meta_timeline(study, type, out_path):\n",
    "    meta_df = pd.DataFrame(columns=[0,1])\n",
    "    meta_df.loc[0,:] = [\"cancer_study_identifier:\", study]\n",
    "    meta_df.loc[1,:] = [\"genetic_alteration_type:\", \"CLINICAL\"]\n",
    "    meta_df.loc[2,:] = [\"datatype:\", \"TIMELINE\"]\n",
    "    meta_df.loc[7,:] = [\"data_filename:\", \"data_timeline_\"+type+\".txt\"]\n",
    "    meta_df.to_csv(join(out_path, \"meta_timeline_\"+type+\".txt\"), sep=\"\\t\", index=False,header=False)\n",
    "\n",
    "def generate_timeline_data_file(in_path, provider, study, out_path, type):\n",
    "    ps = read_metadata_without_fields(join(in_path, provider+\"_metadata-patient_sample.tsv\"))\n",
    "    if type == 'specimen':\n",
    "        out_cols = [\"PATIENT_ID\", \"START_DATE\", \"STOP_DATE\", \"EVENT_TYPE\", \"SAMPLE_ID\",\"SPECIMEN_SITE\", \"SOURCE\"]\n",
    "        ps[\"PATIENT_ID\"], ps[\"SAMPLE_ID\"], ps[\"STOP_DATE\"] = ps[\"patient_id\"], ps[\"sample_id\"], \"\"\n",
    "        ps['START_DATE'], ps['SOURCE'], ps['EVENT_TYPE'] = 0, provider, type.upper()\n",
    "        ps[\"SPECIMEN_SITE\"] = ps[\"collection_site\"]\n",
    "        ids = list(pd.read_csv(join(out_path, \"data_clinical_patient.txt\"), sep=\"\\t\")[\"#Patient Identifier\"])\n",
    "        ps = ps[ps[\"patient_id\"].isin(ids)]\n",
    "        ps[out_cols].to_csv(join(out_path, \"data_timeline_\"+type+\".txt\"), sep=\"\\t\", index=False)\n",
    "    if type==\"treatment\":\n",
    "        treatment = read_metadata_with_fields(join(in_path, \"treatment\", provider+\"_patienttreatment-Sheet1.tsv\"))\n",
    "        dates = ps[[\"patient_id\", \"collection_date\"]]\n",
    "        try:\n",
    "            dates[\"date_time\"] = pd.to_datetime(dates[\"collection_date\"].replace(\"(?i)not provided\", \"\", regex=True).replace(\"(?i)not collected\", \"\", regex=True).str.replace(\" \",\"-\"), format='%b-%y')\n",
    "        except:\n",
    "            try: \n",
    "                dates[\"date_time\"] = pd.to_datetime(dates[\"collection_date\"].replace(\"(?i)not provided\", \"\", regex=True).replace(\"(?i)not collected\", \"\", regex=True).str.replace(\" \",\"-\"), format='%b-%Y')\n",
    "            except:\n",
    "                try:\n",
    "                    dates[\"date_time\"] = pd.to_datetime(dates[\"collection_date\"].replace(\"(?i)not provided\", \"\", regex=True).replace(\"(?i)not collected\", \"\", regex=True).str.replace(\" \",\"-\"), format='%d/%b/%y')\n",
    "                except:\n",
    "                    print(\"Failed to handle the dates\")\n",
    "                    dates[\"date_time\"] = 0\n",
    "                            \n",
    "        treatment = treatment.merge(dates, on=\"patient_id\", how=\"inner\").reset_index(drop=True)\n",
    "        try:\n",
    "            treatment[\"start_date_time\"] = pd.to_datetime(treatment[\"treatment_starting_date\"].str.replace('Not provided', '', flags=re.IGNORECASE).str.replace('Not collected', '', flags=re.IGNORECASE).str.replace(\" \",\"-\"), format='%b-%y')\n",
    "        except:\n",
    "            try: \n",
    "                treatment[\"start_date_time\"] = pd.to_datetime(treatment[\"treatment_starting_date\"].str.replace('Not provided', '', flags=re.IGNORECASE).str.replace('Not collected', '', flags=re.IGNORECASE).str.replace(\" \",\"-\"), format='%b-%Y')\n",
    "            except:\n",
    "                try: \n",
    "                    treatment[\"start_date_time\"] = pd.to_datetime(treatment[\"treatment_starting_date\"].str.replace('Not provided', '', flags=re.IGNORECASE).str.replace('Not collected', '', flags=re.IGNORECASE).str.replace(\" \",\"-\"), format='%d/%b/%y')\n",
    "                except:\n",
    "                    treatment[\"start_date_time\"] = 0\n",
    "        out_cols = [\"PATIENT_ID\", \"START_DATE\", \"STOP_DATE\", \"EVENT_TYPE\",\"TREATMENT_TYPE\", \"AGENT\"]\n",
    "        treatment[\"PATIENT_ID\"] = treatment[\"patient_id\"]\n",
    "        treatment[\"START_DATE\"] = (treatment['start_date_time'] - treatment['date_time']).dt.days\n",
    "        treatment[\"STOP_DATE\"] = pd.to_numeric(treatment[\"START_DATE\"], errors='coerce') + (pd.to_numeric(treatment[\"treatment_duration\"].replace(\"(?i)not provided\", \"0\", regex=True), errors='coerce')*30)\n",
    "        treatment[\"START_DATE\"].fillna(0, inplace=True)\n",
    "        treatment[\"STOP_DATE\"].fillna(0, inplace=True)\n",
    "        treatment[\"EVENT_TYPE\"] = type.upper()\n",
    "        \n",
    "        treatment[\"START_DATE\"] = treatment[\"START_DATE\"].astype(int)\n",
    "        treatment[\"STOP_DATE\"] = treatment[\"STOP_DATE\"].astype(int)\n",
    "        treatment[\"TREATMENT_TYPE\"] = \"Medical Therapy\"\n",
    "        treatment[\"AGENT\"] = treatment[\"treatment_name\"]\n",
    "        \n",
    "        treatment[out_cols].to_csv(join(out_path, \"data_timeline_\"+type+\".txt\"), sep=\"\\t\", index=False)\n",
    "    if type==\"lab_test\":\n",
    "        cyto = read_metadata_with_fields(join(in_path, \"cyto\", provider+\"_cytogenetics-Sheet1.tsv\"))\n",
    "        cyto = cyto.merge(ps[[\"patient_id\", \"sample_id\"]], on=\"sample_id\", how=\"inner\")\n",
    "        out_cols = [\"PATIENT_ID\", \"START_DATE\", \"STOP_DATE\", \"EVENT_TYPE\",\"TEST\", \"RESULT\"]\n",
    "        cyto[\"PATIENT_ID\"], cyto[\"START_DATE\"], cyto[\"STOP_DATE\"] = cyto[\"patient_id\"], 0, \"\"\n",
    "        cyto[\"EVENT_TYPE\"] = type.upper()\n",
    "        cyto[\"TEST\"], cyto[\"RESULT\"] =  cyto['symbol'], cyto['marker_status']\n",
    "        cyto[out_cols].to_csv(join(out_path, \"data_timeline_\"+type+\".txt\"), sep=\"\\t\", index=False)\n",
    "    \n",
    "def generate_timeline_data(in_path, out_path, study, provider):\n",
    "    generate_meta_timeline(study, \"specimen\", out_path)\n",
    "    generate_timeline_data_file(in_path, provider, study, out_path, 'specimen')\n",
    "    if exists(join(in_path, \"treatment\")):\n",
    "        generate_meta_timeline(study, \"treatment\", out_path)\n",
    "        generate_timeline_data_file(in_path, provider, study, out_path, 'treatment')\n",
    "    if exists(join(in_path, \"cyto\")):\n",
    "        generate_meta_timeline(study, \"lab_test\", out_path)\n",
    "        generate_timeline_data_file(in_path, provider, study, out_path, 'lab_test')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T11:56:29.620599Z",
     "start_time": "2023-09-18T11:56:29.546807Z"
    }
   },
   "id": "60be0ec6fb7762c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Meta files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c02b5bf8a670cf8b"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def get_provider_description(provider_name):\n",
    "    if provider_name==\"DFCI-CPDM\":\n",
    "        return \"The Center for Patient Derived Models (CPDM) at Dana-Farber  Cancer Institute (DFCI) is a strategic collaborative research center with the expertise  to generate and characterize patient derived xenografts (PDX), patient derived cell  lines (PDCL - 3D organoid/spheroid and 2D adherent cultures), and acute cell models  drug testing. Through collaboration with major disease groups in the Dana-Farber Cancer Institute, Brigham and Women's Hospital, and Boston Children Hospital Cancer Centers, we have made a large collection of patient derived models of brain tumors, hematologic tumors, and many other solid tumors available to academic and industrial researchers worldwide.\"\n",
    "    df = pd.read_json(\"https://www.cancermodels.org/api/provider_group?abbreviation=eq.\"+provider_name)    \n",
    "    description = str(df[\"description\"][0]).replace(\"\\n\\n\", \" \").replace(\"\\n\", \" \")\n",
    "    if len(description)>=1024:\n",
    "        description = description[0:1020]\n",
    "    return description\n",
    "\n",
    "def get_study_cancer_type(provider):\n",
    "    cancer_types = {\"CCIA\": \"lymph\", \"CHOP\": \"nbl\", \"Curie-BC\": \"brca\", \"Curie-LC\": \"lung\", \"Curie-OC\":\"ovary\", \"HCI-BCM\": \"breast\", \n",
    "                    \"IRCC-CRC\":\"coadread\", \"IRCC-GC\": \"stomach\", \"LIH\": \"brain\", \"MDAnderson-CCH\":\"os\", \"NKI\": \"brca\", \"SANG\":\"bowel\",\n",
    "                    \"UMCG\": \"ovary\", \"UOC-BC\": \"brca\", \"UOM-BC\": \"brca\", \"VHIO-BC\": \"brca\", \"VHIO-CRC\": \"bowel\", \"VHIO-PC\": \"pancreas\"}\n",
    "    #ctype = pd.read_json(\"https://www.cancermodels.org/api/model_metadata?data_source=eq.\"+provider)\n",
    "    #unique_values_count = len(ctype['cancer_system'].unique())\n",
    "    if provider in cancer_types.keys():\n",
    "        #db_df = pd.read_csv(\"cbioportal_type_of_cancer.tsv\")\n",
    "        #ctype = ctype['cancer_system'].unique()[0]\n",
    "        #ctype = process.extract(ctype, db_df['NAME'])[0]\n",
    "        #ctype = db_df[db_df[\"NAME\"] == ctype][\"TYPE_OF_CANCER_ID\"].reset_index(drop=True)[0]\n",
    "        #if ctype==\"\":\n",
    "        #    ctype = \"mixed\"\n",
    "        return cancer_types[provider]\n",
    "    else:\n",
    "        return \"mixed\"\n",
    "\n",
    "def generate_meta_study_file(in_path, study, provider, out_path):\n",
    "    df = pd.read_json(\"https://www.cancermodels.org/api/provider_group?abbreviation=eq.\"+provider)    \n",
    "    if provider!=\"DFCI-CPDM\":\n",
    "        provider_name_full = str(df[\"name\"][0])\n",
    "    elif provider==\"DFCI-CPDM\":\n",
    "        provider_name_full=\"Center for Patient Derived Models, Dana-Farber Cancer Institute\"\n",
    "    cancer_type = get_study_cancer_type(provider)\n",
    "    meta_study_df = pd.DataFrame(columns=[0,1])\n",
    "    meta_study_df.loc[0,:] = [\"type_of_cancer:\", cancer_type] #\"mixed\"]\n",
    "    meta_study_df.loc[1,:] = [\"cancer_study_identifier:\",  study]\n",
    "    meta_study_df.loc[2,:] = [\"name:\", provider_name_full]\n",
    "    meta_study_df.loc[3,:] = [\"description:\", get_provider_description(provider)]\n",
    "    meta_study_df.loc[4,:] = [\"groups:\", \"PUBLIC\"]\n",
    "    #meta_study_df.loc[5,:] = [\"short_name:\", \"PDCMs (\"+provider+\")\"]\n",
    "    meta_study_df.loc[5,:] = [\"reference_genome:\", \"hg38\"]\n",
    "    #meta_study_df.loc[6,:] = [\"add_global_case_list:\", \"true\"]\n",
    "    meta_study_df.to_csv(join(out_path, \"meta_study.txt\"), sep=\"\\t\", index=False,header=False)\n",
    "    \n",
    "def generate_meta_clinical_files(study, out_path, type):\n",
    "    meta_df = pd.DataFrame(columns=[0,1])\n",
    "    meta_df.loc[0,:] = [\"cancer_study_identifier:\", study]\n",
    "    meta_df.loc[1,:] = [\"genetic_alteration_type:\", \"CLINICAL\"]\n",
    "    meta_df.loc[2,:] = [\"datatype:\", type.upper()+\"_ATTRIBUTES\"]\n",
    "    meta_df.loc[3,:] = [\"data_filename:\", \"data_clinical_\"+type+\".txt\"]\n",
    "    meta_df.to_csv(join(out_path, \"meta_clinical_\"+type+\".txt\"), sep=\"\\t\", index=False,header=False)\n",
    "\n",
    "def generate_meta_files(in_path, out_path, provider, study):\n",
    "    generate_meta_study_file(in_path, study, provider, out_path)\n",
    "    generate_meta_clinical_files(study, out_path, \"sample\")\n",
    "    generate_meta_clinical_files(study, out_path, \"patient\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T11:56:29.655373Z",
     "start_time": "2023-09-18T11:56:29.613148Z"
    }
   },
   "id": "2c2c9c8c2d5770a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### main()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2d4c9796a59c948"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def generate_case_lists_script(conf, out_path, study):\n",
    "    if not exists(join(out_path, \"case_lists\")):\n",
    "        makedirs(join(out_path, \"case_lists\"))\n",
    "    #command = \"python3 {} -c {} -d {} -s {} -i {}\".format(script, conf, join(out_path, \"case_lists\"), out_path, study)\n",
    "    main(conf, join(out_path, \"case_lists\"), out_path, study, False, False)\n",
    "\n",
    "def generate_c_bio_portal_files(in_path, out_path, provider):\n",
    "    #case_script = \"/Users/tushar/CancerModels/utils/cbioportal/datahub-study-curation-tools/generate-case-lists/generate_case_lists.py\"\n",
    "    case_conf = \"/Users/tushar/CancerModels/utils/cbioportal/datahub-study-curation-tools/generate-case-lists/case_list_conf.txt\"\n",
    "    study = provider\n",
    "    out_path = join(out_path, study)\n",
    "    if not exists(out_path):\n",
    "        makedirs(out_path)\n",
    "    generate_meta_files(in_path, out_path, provider, study)\n",
    "    generate_clinical_sample(in_path, out_path, provider)\n",
    "    generate_clinical_patient(in_path, out_path, provider)\n",
    "    if provider!=\"CRL\" and not provider.__contains__(\"Curie\"):\n",
    "        generate_timeline_data(in_path, out_path, study, provider)\n",
    "        if exists(join(in_path, \"mut\")):\n",
    "            generate_mutation_files(in_path, study, provider, out_path)\n",
    "        if exists(join(in_path, \"expression\")):\n",
    "            generate_expression_files(in_path, study, provider, out_path)\n",
    "        if exists(join(in_path, \"cna\")):\n",
    "            generate_cna_files(in_path, study, provider, out_path)\n",
    "    generate_case_lists_script( case_conf, out_path, study)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T11:56:29.655621Z",
     "start_time": "2023-09-18T11:56:29.634619Z"
    }
   },
   "id": "c2f1db2a24993f40"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Per provider"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5760ecc26dc9f49f"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating cBioPortal data:   0%|          | 0/7 [00:00<?, ?it/s]/var/folders/_2/g5d3zf4s41g0tvlqkc3_8wjr0000gp/T/ipykernel_51260/364450737.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dates[\"date_time\"] = pd.to_datetime(dates[\"collection_date\"].replace(\"(?i)not provided\", \"\", regex=True).replace(\"(?i)not collected\", \"\", regex=True).str.replace(\" \",\"-\"), format='%b-%y')\n",
      "/var/folders/_2/g5d3zf4s41g0tvlqkc3_8wjr0000gp/T/ipykernel_51260/855994262.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].apply(lambda x: filter_sample_ids(str(x), sample_ids))\n",
      "/var/folders/_2/g5d3zf4s41g0tvlqkc3_8wjr0000gp/T/ipykernel_51260/855994262.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].apply(lambda x: filter_sample_ids(str(x), sample_ids))\n",
      "/var/folders/_2/g5d3zf4s41g0tvlqkc3_8wjr0000gp/T/ipykernel_51260/855994262.py:40: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(file, sep=\"\\t\")\n",
      "/var/folders/_2/g5d3zf4s41g0tvlqkc3_8wjr0000gp/T/ipykernel_51260/855994262.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].apply(lambda x: filter_sample_ids(str(x), sample_ids))\n",
      "Generating cBioPortal data:  14%|█▍        | 1/7 [02:41<16:06, 161.12s/it]/var/folders/_2/g5d3zf4s41g0tvlqkc3_8wjr0000gp/T/ipykernel_51260/364450737.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dates[\"date_time\"] = pd.to_datetime(dates[\"collection_date\"].replace(\"(?i)not provided\", \"\", regex=True).replace(\"(?i)not collected\", \"\", regex=True).str.replace(\" \",\"-\"), format='%b-%y')\n",
      "Generating cBioPortal data: 100%|██████████| 7/7 [02:50<00:00, 24.34s/it] \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, len(providers)), desc =\"Generating cBioPortal data: \"): ## get_dirs will get the provider dirs in updog\n",
    "    provider = providers[i]\n",
    "    generate_c_bio_portal_files(join(home, provider), out_path, provider) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T11:59:20.034790Z",
     "start_time": "2023-09-18T11:56:29.645198Z"
    }
   },
   "id": "768d65aeff0443ab"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T11:59:20.052309Z",
     "start_time": "2023-09-18T11:59:20.025742Z"
    }
   },
   "id": "2f221002003557c6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
